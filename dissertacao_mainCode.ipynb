{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit-Spark Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Spark Lib\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.util import MLUtils\n",
    "\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer, IndexToString\n",
    "from pyspark.ml.feature import VectorAssembler, VectorIndexer\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import LinearSVC, OneVsRest\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.mllib.util import MLUtils\n",
    "\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "        .master(\"local[8]\") \\\n",
    "        .appName(\"MachineLearningIris\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Resultados:\n",
    "    def __init__(self, algoritmo, acuracia, tempo, precisao, fpositivos, recall, parametroA, parametroB):\n",
    "        self.algoritmo = algoritmo \n",
    "        self.acuracia = acuracia\n",
    "        self.tempo = tempo\n",
    "        self.precisao = precisao\n",
    "        self.fpositivos = fpositivos\n",
    "        self.recall = recall\n",
    "        self.parametroA = parametroA\n",
    "        self.parametroB = parametroB\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "class Naive:\n",
    "    def __init__(self, smoothing):\n",
    "        self.smoothing = smoothing \n",
    "        \n",
    "class SVM:\n",
    "    def __init__(self, maxIter, regParam):\n",
    "        self.maxIter = maxIter \n",
    "        self.regParam = regParam\n",
    "        \n",
    "class Tree:\n",
    "    def __init__(self, maxDepth, checkpointInterval):\n",
    "        self.maxDepth = maxDepth \n",
    "        self.checkpointInterval = checkpointInterval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def naive(train, test, param):\n",
    "    \n",
    "    \n",
    "    best = []\n",
    "    \n",
    "    timeList = []\n",
    "    \n",
    "    resul = []\n",
    "    \n",
    "    start_time_total =  time.time()\n",
    "\n",
    "    \n",
    "    for x in param.smoothing:\n",
    "            \n",
    "        \n",
    "        start_time =  time.time()\n",
    "        \n",
    "    \n",
    "        trainer = NaiveBayes(smoothing=x, modelType=\"multinomial\")    \n",
    "\n",
    "        evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\\\n",
    "                metricName=\"accuracy\")\n",
    "\n",
    "        model = trainer.fit(train)\n",
    "\n",
    "        result_nb = model.transform(test)\n",
    "\n",
    "        accuracy_nb = evaluator.evaluate(result_nb) * 100\n",
    "                \n",
    "        timeFinal = time.time() - start_time\n",
    "        \n",
    "        timeList.append(timeFinal)\n",
    "        \n",
    "        print(\"Algorithm: Naive Bayes | Accuracy = %3.1f %% | Time = %3.1f s | Smoothing = %3.1f\" % (accuracy_nb, timeFinal, x))\n",
    "    \n",
    "\n",
    "        # Matriz de Confusão\n",
    "        preds_and_labels = result_nb.select(['prediction','label']).withColumn('label', F.col('label').cast(FloatType())).orderBy('prediction')\n",
    "        preds_and_labels = preds_and_labels.select(['prediction','label'])\n",
    "        metrics = MulticlassMetrics(preds_and_labels.rdd.map(tuple))\n",
    "        \n",
    "        \n",
    "        prec = metrics.precision(1.0) *100\n",
    "        fp = metrics.falsePositiveRate(1.0)*100\n",
    "        rec =  metrics.recall(1.0)*100\n",
    "        \n",
    "        resul.append(Resultados('naive', accuracy_nb, timeFinal, prec, fp, rec, x, None))\n",
    "        \n",
    "        best.append(accuracy_nb)\n",
    "    \n",
    "    \n",
    "    timeTotal = time.time() - start_time_total\n",
    "\n",
    "    \n",
    "    print(\"Tempo Médio: %3.1f s\" % (sum(timeList)/len(timeList)))\n",
    "    print(\"Tempo Total: %3.1f s\" % timeTotal)\n",
    "\n",
    "        \n",
    "    \n",
    "        \n",
    "    \n",
    "    #return max(best)\n",
    "    return resul\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def svm(train, test, param):\n",
    "    \n",
    "    best = []\n",
    "\n",
    "    timeList = []\n",
    "\n",
    "    resul = []\n",
    "\n",
    "    start_time_total =  time.time()\n",
    "    \n",
    "    for x in param.maxIter:\n",
    "        for y in param.regParam:\n",
    "            \n",
    "            start_time =  time.time()\n",
    "\n",
    "    \n",
    "            trainer = LinearSVC(featuresCol='features', labelCol='label',\\\n",
    "                            maxIter=x, regParam=y)\n",
    "\n",
    "            ovr_trainer = OneVsRest(classifier=trainer)\n",
    "\n",
    "\n",
    "            model = ovr_trainer.fit(train)\n",
    "\n",
    "            result_svm = model.transform(test)\n",
    "\n",
    "\n",
    "            evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\\\n",
    "                    metricName=\"accuracy\")\n",
    "\n",
    "            accuracy_svm = evaluator.evaluate(result_svm) * 100\n",
    "            \n",
    "            timeFinal = time.time() - start_time\n",
    "\n",
    "            timeList.append(timeFinal)\n",
    "\n",
    "            print(\"Algorithm: SVM | Accuracy = %3.1f %% | Time = %3.1f s | maxIter = %3.1f | regParam = %3.1f\" % (accuracy_svm, timeFinal, x, y))\n",
    "\n",
    "            # Matriz de Confusão\n",
    "            preds_and_labels = result_svm.select(['prediction','label']).withColumn('label', F.col('label').cast(FloatType())).orderBy('prediction')\n",
    "            preds_and_labels = preds_and_labels.select(['prediction','label'])\n",
    "            metrics = MulticlassMetrics(preds_and_labels.rdd.map(tuple))\n",
    "        \n",
    "        \n",
    "            prec = metrics.precision(1.0) *100\n",
    "            fp = metrics.falsePositiveRate(1.0)*100\n",
    "            rec =  metrics.recall(1.0) *100\n",
    "            \n",
    "            \n",
    "            resul.append(Resultados('svm', accuracy_svm, timeFinal, prec, fp, rec, x, y))\n",
    "\n",
    "            \n",
    "            best.append(accuracy_svm)\n",
    "    \n",
    "    timeTotal = time.time() - start_time_total\n",
    "            \n",
    "    print(\"Tempo Médio: %3.1f s\" % (sum(timeList)/len(timeList)))\n",
    "    print(\"Tempo Total: %3.1f s\" % timeTotal)\n",
    "\n",
    "\n",
    "\n",
    "#    return max(best)\n",
    "    return resul\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decTree(train, test, param):\n",
    "    \n",
    "    best = []\n",
    "\n",
    "    timeList = []\n",
    "    \n",
    "    resul = []\n",
    "\n",
    "    start_time_total =  time.time()\n",
    "    \n",
    "    for x in param.maxDepth:\n",
    "        for y in param.checkpointInterval:\n",
    "            \n",
    "            start_time =  time.time()\n",
    "\n",
    "    \n",
    "            trainer = DecisionTreeClassifier(featuresCol='features', labelCol='label', predictionCol='prediction', probabilityCol='probability',\\\n",
    "                                             rawPredictionCol='rawPrediction', maxDepth=x, maxBins=32, minInstancesPerNode=1, minInfoGain=0.0,\\\n",
    "                                             maxMemoryInMB=256, cacheNodeIds=False, checkpointInterval=y, impurity='gini', seed=None)\n",
    "\n",
    "\n",
    "            evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\\\n",
    "                        metricName=\"accuracy\")\n",
    "\n",
    "            model = trainer.fit(train)\n",
    "\n",
    "            result_dt = model.transform(test)\n",
    "    \n",
    "            accuracy_dt = evaluator.evaluate(result_dt) * 100\n",
    "        \n",
    "            timeFinal = time.time() - start_time\n",
    "            \n",
    "            timeList.append(timeFinal)\n",
    "    \n",
    "            #print(\"Decision Tree: accuracy = %3.1f %%\" % accuracy_dt)\n",
    "        \n",
    "            print(\"Algorithm: decTree | Accuracy = %3.1f %% | Time = %3.1f s | maxDepth = %3.1f | checkpointInterval = %3.1f\" % (accuracy_dt, timeFinal, x, y))\n",
    "\n",
    "            # Matriz de Confusão\n",
    "            preds_and_labels = result_dt.select(['prediction','label']).withColumn('label', F.col('label').cast(FloatType())).orderBy('prediction')\n",
    "            preds_and_labels = preds_and_labels.select(['prediction','label'])\n",
    "            metrics = MulticlassMetrics(preds_and_labels.rdd.map(tuple))\n",
    "        \n",
    "        \n",
    "            prec = metrics.precision(1.0) *100\n",
    "            fp = metrics.falsePositiveRate(1.0)*100\n",
    "            rec =  metrics.recall(1.0) *100\n",
    "            \n",
    "            \n",
    "            resul.append(Resultados('dtree', accuracy_dt, timeFinal, prec, fp, rec, x, y))\n",
    "    \n",
    "    timeTotal = time.time() - start_time_total\n",
    "            \n",
    "    print(\"Tempo Médio: %3.1f s\" % (sum(timeList)/len(timeList)))\n",
    "    print(\"Tempo Total: %3.1f s\" % timeTotal)\n",
    "    \n",
    "    \n",
    "#    return accuracy_dt\n",
    "    return resul\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função que Executa Todos os Algoritmos de ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def autoChoice(train, test, choice, naivep, svmp, dtreep):\n",
    "    \n",
    "    resul=[]\n",
    "    \n",
    "    \n",
    "    if choice == 'auto':\n",
    "        resul.append(Resultados('naive' ,naive(train, test, naivep)))\n",
    "        resul.append(Resultados('svm', svm(train, test, svmp)))\n",
    "        resul.append(Resultados('DecisionTree', decTree(train, test, dtreep)))\n",
    "        \n",
    "        resul.sort(key=lambda x: x.acuracia, reverse=True)\n",
    "        print(resul[0].algoritmo, resul[0].acuracia, sep =' ' )\n",
    "        \n",
    "        \n",
    "        \n",
    "    elif choice == 'naive':\n",
    "        return naive(train, test, naivep)\n",
    "        #print(\"A acurácia da Naive Bayes: %3.1f %%\" % naive(train, test, naivep))\n",
    "    elif choice == 'svm':\n",
    "        return svm(train, test, svmp)\n",
    "        #print(\"A acurácia da SVM: %3.1f %%\" % svm(train, test, svmp))\n",
    "    elif choice == 'tree':\n",
    "        return decTree(train, test, dtreep)\n",
    "        #print(\"A acurácia da Decision Tree: %3.1f %%\" % decTree(train, test, dtreep))\n",
    "    else:\n",
    "        print(\"Opção Inválida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função que Gera o Gráfico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphic(resul):\n",
    "\n",
    "    x=[]\n",
    "    y=[]\n",
    "\n",
    "    for i in range(0,len(resul)):\n",
    "        y.append(resul[i].acuracia)\n",
    "\n",
    "    for k in range(0,len(resul)):\n",
    "        x.append(resul[k].parametroA)\n",
    "\n",
    "    x = np.array(x)\n",
    "    #x = range(0,len(resul))\n",
    "    y = np.array(y)\n",
    "\n",
    "    #print(y)\n",
    "    \n",
    "    df=pd.DataFrame({'Smooth': x, 'Acurácia %': y })\n",
    "\n",
    "    # Draw line chart with dashed line\n",
    "    plt.plot( 'Smooth', 'Acurácia %', data=df, linestyle='solid')\n",
    "\n",
    "    plt.title(\"Gráfico de Acurácia\", loc=\"left\")\n",
    "    plt.xlabel(\"Valor Smooth\")\n",
    "    plt.ylabel(\"Acurácia %\")\n",
    "\n",
    "    # Show graph\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Datasets Marcados com \"OK\", são os que já estão tratados e testados\n",
    "\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').\\\n",
    "#            load('/home/tiago/Mestrado/Dissertacao/dataset/iris.data')#OK # Varia\n",
    "\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').\\\n",
    "#            load('/home/tiago/Mestrado/Dissertacao/dataset/glass.data') # OK # Varia\n",
    "\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').\\\n",
    "#            load('/home/tiago/Mestrado/Dissertacao/dataset/sonar.data')#OK # Varia\n",
    "\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').\\\n",
    "#            load('/home/tiago/Mestrado/Dissertacao/dataset/breast-cancer-wisconsin.data')#OK # Estatico\n",
    "\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').\\\n",
    "#            load('/home/tiago/Mestrado/Dissertacao/dataset/lymphography.data')#OK # Estatico\n",
    "\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').\\\n",
    "#            load('/home/tiago/Mestrado/Dissertacao/dataset/balance-scale.data')#OK # Estatico\n",
    "\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').\\\n",
    "#            load('/home/tiago/Mestrado/Dissertacao/dataset/balance-scale2.data')#OK # Estatico\n",
    "\n",
    "orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').\\\n",
    "            load('/home/tiago/Mestrado/Dissertacao/dataset/breastt2.data')#\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_sample = 0.7\n",
    "test_sample = 0.3\n",
    "\n",
    "# 'auto'  = Testa tudo\n",
    "# 'tree'  = Decision Tree\n",
    "# 'naive' = Naive Bayes\n",
    "# 'svm'   = SVM\n",
    "choice = 'naive'\n",
    "\n",
    "# Parâmetros Naive\n",
    "# Nome = Smoothing\n",
    "#smoothing = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "smoothing = [round(x * 0.1, 1) for x in range(0, 100)]\n",
    "\n",
    "#smoothing = [1, 2, 3]\n",
    "naiveParam = Naive(smoothing)\n",
    "\n",
    "# Parâmetros SVM\n",
    "maxIter = [80,90,100]\n",
    "regParam = [0.1,0.2,0.3]\n",
    "svmParam = SVM(maxIter, regParam)\n",
    "\n",
    "# Parâmetros Decision Tree\n",
    "# Deapht / MaxIter\n",
    "maxDepth = [1,2,3,4,5]\n",
    "MaxIter = [10,15,20]\n",
    "dtreeParam = Tree(maxDepth, MaxIter)\n",
    "\n",
    "################\n",
    "\n",
    "\n",
    "#amostra = \"\"\n",
    "#execucao = \"dtree-MD-custom-30-40-CP-custom-15-30\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-Processamento/Tratamento Padrão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "Data type string of column I0 is not supported.\nData type string of column PA500 is not supported.\nData type string of column HFS is not supported.\nData type string of column DA is not supported.\nData type string of column Area is not supported.\nData type string of column A/DA is not supported.\nData type string of column Max IP is not supported.\nData type string of column DR is not supported.\nData type string of column P is not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-c65ffd6d9701>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m             outputCol='features')\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0massembler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"features\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: Data type string of column I0 is not supported.\nData type string of column PA500 is not supported.\nData type string of column HFS is not supported.\nData type string of column DA is not supported.\nData type string of column Area is not supported.\nData type string of column A/DA is not supported.\nData type string of column Max IP is not supported.\nData type string of column DR is not supported.\nData type string of column P is not supported."
     ]
    }
   ],
   "source": [
    "indexer = StringIndexer(inputCol=\"class\", outputCol=\"label\").fit(orig_data)\n",
    "label_data = indexer.transform(orig_data)\n",
    "\n",
    "labelReverse = IndexToString().setInputCol(\"label\")\n",
    "\n",
    "label_data = label_data.drop(\"class\")\n",
    "\n",
    "ignore = ['label']\n",
    "list = [x for x in label_data.columns if x not in ignore]\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "            inputCols=list,\n",
    "            outputCol='features')\n",
    "\n",
    "data = (assembler.transform(label_data).select(\"label\",\"features\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomSplit Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(train, test) = data.randomSplit([train_sample, test_sample], 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resul = []\n",
    "resul = autoChoice(train, test, choice, naiveParam, svmParam, dtreeParam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "graphic(resul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibe os Melhores Resultados em Ordem Decrescente\n",
    "resul.sort(key=lambda x: x.acuracia, reverse=True)\n",
    "for i in range(10):\n",
    "    print(\"Algorithm: %s | Accuracy = %3.1f %% | Time = %3.1f s | Smoothing = %3.1f\" % (resul[i].algoritmo, resul[i].acuracia, resul[i].tempo, resul[i].parametroA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime Outros Resultados do Melhor Modelo\n",
    "print(\"Algorithm: %s | Precisão = %3.1f %% | False Positive = %3.1f %% | Recall = %3.1f %%\" % (resul[0].algoritmo, resul[0].precisao, resul[0].fpositivos, resul[0].recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
