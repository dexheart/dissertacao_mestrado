{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit-Spark Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Spark Lib\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.util import MLUtils\n",
    "\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer, IndexToString\n",
    "from pyspark.ml.feature import VectorAssembler, VectorIndexer\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import LinearSVC, OneVsRest\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.mllib.util import MLUtils\n",
    "\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .appName(\"FitSpark\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Resultados:\n",
    "    def __init__(self, algoritmo, acuracia, tempo, precisao, fpositivos, recall, parametroA, parametroB):\n",
    "        self.algoritmo = algoritmo \n",
    "        self.acuracia = acuracia\n",
    "        self.tempo = tempo\n",
    "        self.precisao = precisao\n",
    "        self.fpositivos = fpositivos\n",
    "        self.recall = recall\n",
    "        self.parametroA = parametroA\n",
    "        self.parametroB = parametroB\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "class Naive:\n",
    "    def __init__(self, smoothing):\n",
    "        self.smoothing = smoothing \n",
    "        \n",
    "class SVM:\n",
    "    def __init__(self, maxIter, regParam):\n",
    "        self.maxIter = maxIter \n",
    "        self.regParam = regParam\n",
    "        \n",
    "class Tree:\n",
    "    def __init__(self, maxDepth, maxBin):\n",
    "        self.maxDepth = maxDepth \n",
    "        self.maxBin = maxBin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def naive(train, test, param):\n",
    "    \n",
    "    best = []   # Lista do Melhor Resultado\n",
    "    timeList = [] # Lista do Tempo de Treinamento de cada Modelo\n",
    "    resul = [] # Lista de Todas informações na lista de Objetos\n",
    "    \n",
    "    start_time_total =  time.time()\n",
    "  \n",
    "    for x in param.smoothing:\n",
    "            \n",
    "        start_time =  time.time()\n",
    "        \n",
    "        # Define o Modelo \n",
    "        trainer = NaiveBayes(smoothing=x, modelType=\"multinomial\")    \n",
    "        evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\\\n",
    "                metricName=\"accuracy\")\n",
    "        \n",
    "        # Realiza o Treinamento e Calcula Acuracia\n",
    "        model = trainer.fit(train)\n",
    "        result_nb = model.transform(test)\n",
    "        accuracy_nb = evaluator.evaluate(result_nb) * 100\n",
    "             \n",
    "        timeFinal = time.time() - start_time\n",
    "        timeList.append(timeFinal)\n",
    "        \n",
    "        print(\"Algorithm: Naive Bayes | Accuracy = %3.1f %% | Time = %3.1f s | Smoothing = %3.1f\" % (accuracy_nb, timeFinal, x))\n",
    "    \n",
    "        # Matriz de Confusão\n",
    "        preds_and_labels = result_nb.select(['prediction','label']).withColumn('label', F.col('label').cast(FloatType())).orderBy('prediction')\n",
    "        preds_and_labels = preds_and_labels.select(['prediction','label'])\n",
    "        metrics = MulticlassMetrics(preds_and_labels.rdd.map(tuple))\n",
    "        \n",
    "        \n",
    "        prec = metrics.precision(1.0) *100\n",
    "        fp = metrics.falsePositiveRate(1.0)*100\n",
    "        rec =  metrics.recall(1.0)*100\n",
    "        \n",
    "        resul.append(Resultados('naive', accuracy_nb, timeFinal, prec, fp, rec, x, None))\n",
    "        \n",
    "        best.append(accuracy_nb)\n",
    "    \n",
    "    \n",
    "    timeTotal = time.time() - start_time_total\n",
    "\n",
    "    print(\"Tempo Médio: %3.1f s\" % (sum(timeList)/len(timeList)))\n",
    "    print(\"Tempo Total: %3.1f s\" % timeTotal)\n",
    "  \n",
    "    return resul\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def svm(train, test, param):\n",
    "    \n",
    "    best = []\n",
    "\n",
    "    timeList = []\n",
    "\n",
    "    resul = []\n",
    "\n",
    "    start_time_total =  time.time()\n",
    "    \n",
    "    for x in param.maxIter:\n",
    "        for y in param.regParam:\n",
    "            \n",
    "            start_time =  time.time()\n",
    "\n",
    "    \n",
    "            trainer = LinearSVC(featuresCol='features', labelCol='label',\\\n",
    "                            maxIter=x, regParam=y)\n",
    "\n",
    "            ovr_trainer = OneVsRest(classifier=trainer)\n",
    "\n",
    "\n",
    "            model = ovr_trainer.fit(train)\n",
    "\n",
    "            result_svm = model.transform(test)\n",
    "\n",
    "\n",
    "            evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\\\n",
    "                    metricName=\"accuracy\")\n",
    "\n",
    "            accuracy_svm = evaluator.evaluate(result_svm) * 100\n",
    "            \n",
    "            timeFinal = time.time() - start_time\n",
    "\n",
    "            timeList.append(timeFinal)\n",
    "\n",
    "            print(\"Algorithm: SVM | Accuracy = %3.1f %% | Time = %3.1f s | maxIter = %3.1f | regParam = %3.1f\" % (accuracy_svm, timeFinal, x, y))\n",
    "\n",
    "            # Matriz de Confusão\n",
    "            preds_and_labels = result_svm.select(['prediction','label']).withColumn('label', F.col('label').cast(FloatType())).orderBy('prediction')\n",
    "            preds_and_labels = preds_and_labels.select(['prediction','label'])\n",
    "            metrics = MulticlassMetrics(preds_and_labels.rdd.map(tuple))\n",
    "        \n",
    "        \n",
    "            prec = metrics.precision(1.0) *100\n",
    "            fp = metrics.falsePositiveRate(1.0)*100\n",
    "            rec =  metrics.recall(1.0) *100\n",
    "            \n",
    "            \n",
    "            resul.append(Resultados('svm', accuracy_svm, timeFinal, prec, fp, rec, x, y))\n",
    "\n",
    "            \n",
    "            best.append(accuracy_svm)\n",
    "    \n",
    "    timeTotal = time.time() - start_time_total\n",
    "            \n",
    "    print(\"Tempo Médio: %3.1f s\" % (sum(timeList)/len(timeList)))\n",
    "    print(\"Tempo Total: %3.1f s\" % timeTotal)\n",
    "\n",
    "\n",
    "\n",
    "#    return max(best)\n",
    "    return resul\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decTree(train, test, param):\n",
    "    \n",
    "    best = [] # Lista do Melhor Resultado\n",
    "    timeList = [] # Lista do Tempo de Treinamento de cada Modelo\n",
    "    resul = [] # Lista de Todas informações na lista de Objetos\n",
    "\n",
    "    start_time_total =  time.time()\n",
    "    \n",
    "    for x in param.maxDepth:\n",
    "        for y in param.maxBin:\n",
    "            \n",
    "            start_time =  time.time()\n",
    "            \n",
    "            # Define o Modelo \n",
    "            trainer = DecisionTreeClassifier(featuresCol='features', labelCol='label', predictionCol='prediction', probabilityCol='probability',\\\n",
    "                                             rawPredictionCol='rawPrediction', maxDepth=x, maxBins=y,\\\n",
    "                                             maxMemoryInMB=1024, cacheNodeIds=False, impurity='gini')\n",
    "\n",
    "\n",
    "            evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\\\n",
    "                        metricName=\"accuracy\")\n",
    "\n",
    "            # Realiza o Treinamento e Calcula Acuracia\n",
    "            model = trainer.fit(train)\n",
    "            result_dt = model.transform(test)\n",
    "            accuracy_dt = evaluator.evaluate(result_dt) * 100\n",
    "        \n",
    "            timeFinal = time.time() - start_time\n",
    "            \n",
    "            timeList.append(timeFinal)\n",
    "        \n",
    "            print(\"Algorithm: decTree | Accuracy = %3.1f %% | Time = %3.1f s | maxDepth = %3.1f | maxBin = %3.1f\" % (accuracy_dt, timeFinal, x, y))\n",
    "\n",
    "            # Matriz de Confusão\n",
    "            preds_and_labels = result_dt.select(['prediction','label']).withColumn('label', F.col('label').cast(FloatType())).orderBy('prediction')\n",
    "            preds_and_labels = preds_and_labels.select(['prediction','label'])\n",
    "            metrics = MulticlassMetrics(preds_and_labels.rdd.map(tuple))\n",
    "        \n",
    "            prec = metrics.precision(1.0) *100\n",
    "            fp = metrics.falsePositiveRate(1.0)*100\n",
    "            rec =  metrics.recall(1.0) *100  \n",
    "            \n",
    "            resul.append(Resultados('dtree', accuracy_dt, timeFinal, prec, fp, rec, x, y))\n",
    "            \n",
    "            best.append(accuracy_dt)\n",
    "    \n",
    "    timeTotal = time.time() - start_time_total\n",
    "            \n",
    "    print(\"Tempo Médio: %3.1f s\" % (sum(timeList)/len(timeList)))\n",
    "    print(\"Tempo Total: %3.1f s\" % timeTotal)\n",
    "    \n",
    "    return resul\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função que Executa Todos os Algoritmos de ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def autoChoice(train, test, choice, naivep, svmp, dtreep):\n",
    "    \n",
    "    resul=[]\n",
    "    \n",
    "    \n",
    "    if choice == 'auto':\n",
    "        resul.append(Resultados('naive' ,naive(train, test, naivep)))\n",
    "        resul.append(Resultados('svm', svm(train, test, svmp)))\n",
    "        resul.append(Resultados('DecisionTree', decTree(train, test, dtreep)))\n",
    "        \n",
    "        resul.sort(key=lambda x: x.acuracia, reverse=True)\n",
    "        print(resul[0].algoritmo, resul[0].acuracia, sep =' ' )\n",
    "        \n",
    "        \n",
    "        \n",
    "    elif choice == 'naive':\n",
    "        return naive(train, test, naivep)\n",
    "        #print(\"A acurácia da Naive Bayes: %3.1f %%\" % naive(train, test, naivep))\n",
    "    elif choice == 'svm':\n",
    "        return svm(train, test, svmp)\n",
    "        #print(\"A acurácia da SVM: %3.1f %%\" % svm(train, test, svmp))\n",
    "    elif choice == 'tree':\n",
    "        return decTree(train, test, dtreep)\n",
    "        #print(\"A acurácia da Decision Tree: %3.1f %%\" % decTree(train, test, dtreep))\n",
    "    else:\n",
    "        print(\"Opção Inválida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função que Gera o Gráfico 2D (Apenas para Naive Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def graphic_2d_naive(resul):\n",
    "\n",
    "    x=[]\n",
    "    y=[]\n",
    "\n",
    "    for i in range(0,len(resul)):\n",
    "        y.append(resul[i].acuracia)\n",
    "        x.append(resul[i].parametroA)\n",
    "\n",
    "\n",
    "    x = np.array(x)\n",
    "    #x = range(0,len(resul))\n",
    "    y = np.array(y)\n",
    "\n",
    "    #print(y)\n",
    "    \n",
    "    df=pd.DataFrame({'Smoothing': x, 'Accuracy %': y })\n",
    "\n",
    "    # Draw line chart with dashed line\n",
    "    plt.plot( 'Smoothing', 'Accuracy %', data=df, linestyle='solid')\n",
    "\n",
    "    plt.title(\"Iris Dataset\", loc=\"left\", fontsize=20)\n",
    "    plt.xlabel(\"Smoothing\", fontsize=16)\n",
    "    plt.ylabel(\"Accuracy %\", fontsize=16)\n",
    "    plt.savefig(\"figura-5.png\")\n",
    "\n",
    "    # Show graph\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função que Gera o Gráfico 3D (Para SVM e Decision Tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de Gráfico Ajustado para SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def graphic_3d_svm(resul):\n",
    "\n",
    "    x=[]\n",
    "    y=[]\n",
    "    z=[]\n",
    "\n",
    "    for i in range(0,len(resul)):\n",
    "        y.append(resul[i].parametroA)\n",
    "        x.append(resul[i].parametroB)\n",
    "        z.append(resul[i].acuracia)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca(projection='3d')\n",
    "    #ax.set_title('Glass Dataset', fontsize=20)\n",
    "    #ax.set_title('Ionosphere Dataset', fontsize=20)\n",
    "    #ax.set_title('Mammographic Masses Dataset', fontsize=20)\n",
    "    ax.set_title('Libras Dataset', fontsize=20)\n",
    "    ax.set_xlabel('RegParam', fontsize=16)\n",
    "    ax.set_ylabel('MaxIter', fontsize=16)\n",
    "    ax.set_zlabel('Accuracy %', fontsize=16)\n",
    "    surf = ax.plot_trisurf(x, y, z, cmap=plt.cm.magma, linewidth=0.2)\n",
    "    fig.colorbar( surf, shrink=0.5, aspect=5, pad = 0.15)\n",
    "    #fig.savefig(\"figura-10.png\")  # glass\n",
    "    #fig.savefig(\"figura-11.png\") # ionosphere\n",
    "    #fig.savefig(\"figura-12.png\") # mammographic_masses\n",
    "    #fig.savefig(\"figura-13.png\") # libras\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de Gráfico Ajustado para Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def graphic_3d_tree(resul):\n",
    "\n",
    "    x=[]\n",
    "    y=[]\n",
    "    z=[]\n",
    "\n",
    "    for i in range(0,len(resul)):\n",
    "        x.append(resul[i].parametroA)\n",
    "        y.append(resul[i].parametroB)\n",
    "        z.append(resul[i].acuracia)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca(projection='3d')\n",
    "    #ax.set_title('WineQuality-White Dataset', fontsize=20) #figura-8\n",
    "    ax.set_title('WineQuality-Red Dataset', fontsize=20)  #figura-9\n",
    "\n",
    "    ax.set_xlabel('maxDepth', fontsize=16)\n",
    "    ax.set_ylabel('maxBin', fontsize=16)\n",
    "    ax.set_zlabel('Accuracy %', fontsize=16)\n",
    "    surf = ax.plot_trisurf(x, y, z, cmap=plt.cm.plasma, linewidth=0.2)\n",
    "    fig.colorbar( surf, shrink=0.5, aspect=5, pad = 0.15)\n",
    "    #fig.savefig(\"figura-8.png\")\n",
    "    fig.savefig(\"figura-9.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Datasets Marcados com \"OK\", são os que já estão tratados e testados\n",
    "\n",
    "########################################################################################\n",
    "                                    #NAIVE BAYES\n",
    "\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').\\\n",
    "#            load('/home/tiago/Mestrado/Dissertacao/dataset/iris.data')#OK # Varia # Acuracia Maxima: 98%\n",
    "\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').\\\n",
    "#            load('/home/tiago/Mestrado/Dissertacao/dataset/glass.data') # OK # Varia # Acuracia Maxima: 80.5\n",
    "\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').\\\n",
    "#            load('/home/tiago/Mestrado/Dissertacao/dataset/sonar.data')#OK # Varia # Acuracia Maxima: 77.8\n",
    "\n",
    "########################################################################################\n",
    "\n",
    "\n",
    "########################################################################################\n",
    "                                    #Decision Tree\n",
    "\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').load('/home/tiago/Mestrado/Dissertacao/dataset/wine-red.data')\n",
    "# ESSE É WHITE: Accuracy = 62.2 %\n",
    "# Tempo Total Com Distribuição: 462.5 s\n",
    "# Tempo Total Sem Distribuição: 1365.0 s\n",
    "\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').load('/home/tiago/Mestrado/Dissertacao/dataset/wine-white.data')\n",
    "# ESSE É RED: Accuracy = 58.6 %\n",
    "# Tempo Total Com Distribuicao: 820.7 s\n",
    "# Tempo Total Sem Distribuição: 2009.8 s\n",
    "\n",
    "\n",
    "########################################################################################\n",
    "\n",
    "########################################################################################\n",
    "                                    #SVM\n",
    "# Glass\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').load('/home/tiago/Mestrado/Dissertacao/dataset/glass.data') \n",
    "# Accuracy = 76.6 % / Tempo Total Com distribuição: 1353.1 s / Tempo Total Sem distribuição: 3441.9 s\n",
    "\n",
    "# Ionosphere\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').load('/home/tiago/Mestrado/Dissertacao/dataset/ionosphere.data') \n",
    "# Accuracy = 89.9 % / Tempo Total Com Distribuição: 256.7 s / Tempo Total Sem distribuição: 638.2\n",
    "\n",
    "# Mammographic\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').load('/home/tiago/Mestrado/Dissertacao/dataset/mammographic_masses.data') \n",
    "# Accuracy = 84.1 % / Tempo Total Com Distribuição: 346.7 s / Tempo Total Sem distribuição: 753.4\n",
    "\n",
    "orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').load('/home/tiago/Mestrado/Dissertacao/dataset/libras.data') \n",
    "# Accuracy = 64.0 % / Tempo Total Com Distribuição: 2641.9 s / Tempo Total Sem distribuição: 6328.5\n",
    "\n",
    "########################################################################################\n",
    "\n",
    "\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').\\\n",
    "#            load('/home/tiago/Mestrado/Dissertacao/dataset/breast-cancer-wisconsin.data')#OK # Estatico\n",
    "\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').\\\n",
    "#            load('/home/tiago/Mestrado/Dissertacao/dataset/lymphography.data')#OK # Estatico\n",
    "\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').\\\n",
    "#            load('/home/tiago/Mestrado/Dissertacao/dataset/balance-scale.data')#OK # Estatico\n",
    "\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').\\\n",
    "#            load('/home/tiago/Mestrado/Dissertacao/dataset/balance-scale2.data')#OK # Estatico\n",
    "\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').\\\n",
    "#            load('/home/tiago/Mestrado/Dissertacao/dataset/ecoli.data')#\n",
    "\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').\\\n",
    "#            load('/home/tiago/Mestrado/Dissertacao/dataset/yeast.data')#\n",
    "\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').\\\n",
    "#            load('/home/tiago/Mestrado/Dissertacao/dataset/wine-white.data')#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_sample = 0.7\n",
    "test_sample = 0.3\n",
    "\n",
    "# 'auto'  = Testa tudo\n",
    "# 'tree'  = Decision Tree\n",
    "# 'naive' = Naive Bayes\n",
    "# 'svm'   = SVM\n",
    "choice = 'svm'\n",
    "\n",
    "# Parâmetros Naive\n",
    "# Nome = Smoothing\n",
    "#smoothing = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "smoothing = [round(x * 0.1, 1) for x in range(0, 100)]\n",
    "naiveParam = Naive(smoothing)\n",
    "\n",
    "# Parâmetros SVM\n",
    "maxIter = [90,100,110,120,130]\n",
    "regParam = [0.0,0.5,1.0]\n",
    "svmParam = SVM(maxIter, regParam)\n",
    "\n",
    "# Parâmetros Decision Tree\n",
    "# Deapht / MaxIter\n",
    "maxDepth = [x for x in range(1, 31)] # 31 é o máximo\n",
    "maxBin = [32,64,128,256,512,1024]\n",
    "dtreeParam = Tree(maxDepth, maxBin)\n",
    "\n",
    "################\n",
    "\n",
    "\n",
    "#amostra = \"\"\n",
    "#execucao = \"dtree-MD-custom-30-40-CP-custom-15-30\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-Processamento/Tratamento Padrão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol=\"class\", outputCol=\"label\").fit(orig_data)\n",
    "label_data = indexer.transform(orig_data)\n",
    "\n",
    "labelReverse = IndexToString().setInputCol(\"label\")\n",
    "\n",
    "label_data = label_data.drop(\"class\")\n",
    "\n",
    "ignore = ['label']\n",
    "list = [x for x in label_data.columns if x not in ignore]\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "            inputCols=list,\n",
    "            outputCol='features')\n",
    "\n",
    "data = (assembler.transform(label_data).select(\"label\",\"features\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomSplit Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(train, test) = data.randomSplit([train_sample, test_sample], 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-48f06a3c1584>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresul\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresul\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoChoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchoice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnaiveParam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvmParam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtreeParam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-466950838e15>\u001b[0m in \u001b[0;36mautoChoice\u001b[0;34m(train, test, choice, naivep, svmp, dtreep)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m#print(\"A acurácia da Naive Bayes: %3.1f %%\" % naive(train, test, naivep))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mchoice\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svm'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;31m#print(\"A acurácia da SVM: %3.1f %%\" % svm(train, test, svmp))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mchoice\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tree'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-223ae42e798c>\u001b[0m in \u001b[0;36msvm\u001b[0;34m(train, test, param)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0movr_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mresult_svm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/ml/classification.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m   2922\u001b[0m         \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mThreadPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetParallelism\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumClasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2924\u001b[0;31m         \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainSingleClass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumClasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2926\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandlePersistence\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         '''\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "resul = []\n",
    "resul = autoChoice(train, test, choice, naiveParam, svmParam, dtreeParam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#graphic_2d_naive(resul)\n",
    "#graphic_3d_tree(resul)\n",
    "#graphic_3d_svm(resul)\n",
    "\n",
    "if choice == 'naive':\n",
    "    graphic_2d_naive(resul)\n",
    "elif choice == 'svm':\n",
    "    graphic_3d_svm(resul)\n",
    "elif choice == 'tree':\n",
    "    graphic_3d_tree(resul)\n",
    "else:\n",
    "    print(\"Opção Inválida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Exibe os Melhores Resultados em Ordem Decrescente\n",
    "resul.sort(key=lambda x: x.acuracia, reverse=True)\n",
    "for i in range(5):\n",
    "    print(\"Algorithm: %s | Accuracy = %3.1f %% | Time = %3.1f s | ParametroA = %3.1f | ParametroB = %3.1f\" % (resul[i].algoritmo, resul[i].acuracia, resul[i].tempo, resul[i].parametroA, resul[i].parametroB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime Outros Resultados do Melhor Modelo\n",
    "print(\"Algorithm: %s | Precisão = %3.1f %% | False Positive = %3.1f %% | Recall = %3.1f %%\" % (resul[0].algoritmo, resul[0].precisao, resul[0].fpositivos, resul[0].recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
