{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit-Spark Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T21:55:48.715082Z",
     "iopub.status.busy": "2022-11-16T21:55:48.714530Z",
     "iopub.status.idle": "2022-11-16T21:55:50.268764Z",
     "shell.execute_reply": "2022-11-16T21:55:50.267333Z",
     "shell.execute_reply.started": "2022-11-16T21:55:48.714953Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Spark Lib\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.util import MLUtils\n",
    "\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer, IndexToString\n",
    "from pyspark.ml.feature import VectorAssembler, VectorIndexer\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import LinearSVC, OneVsRest\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.mllib.util import MLUtils\n",
    "\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T21:55:50.270309Z",
     "iopub.status.busy": "2022-11-16T21:55:50.270074Z",
     "iopub.status.idle": "2022-11-16T21:55:53.923442Z",
     "shell.execute_reply": "2022-11-16T21:55:53.921835Z",
     "shell.execute_reply.started": "2022-11-16T21:55:50.270281Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/16 18:55:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .appName(\"FitSpark\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T21:55:53.930781Z",
     "iopub.status.busy": "2022-11-16T21:55:53.930241Z",
     "iopub.status.idle": "2022-11-16T21:55:53.942409Z",
     "shell.execute_reply": "2022-11-16T21:55:53.941014Z",
     "shell.execute_reply.started": "2022-11-16T21:55:53.930715Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Resultados:\n",
    "    def __init__(self, algoritmo, acuracia, tempo, precisao, fpositivos, recall, parametroA, parametroB):\n",
    "        self.algoritmo = algoritmo \n",
    "        self.acuracia = acuracia\n",
    "        self.tempo = tempo\n",
    "        self.precisao = precisao\n",
    "        self.fpositivos = fpositivos\n",
    "        self.recall = recall\n",
    "        self.parametroA = parametroA\n",
    "        self.parametroB = parametroB\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "class Naive:\n",
    "    def __init__(self, smoothing):\n",
    "        self.smoothing = smoothing \n",
    "        \n",
    "class SVM:\n",
    "    def __init__(self, maxIter, regParam):\n",
    "        self.maxIter = maxIter \n",
    "        self.regParam = regParam\n",
    "        \n",
    "class Tree:\n",
    "    def __init__(self, maxDepth, maxBin):\n",
    "        self.maxDepth = maxDepth \n",
    "        self.maxBin = maxBin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T21:55:53.943731Z",
     "iopub.status.busy": "2022-11-16T21:55:53.943576Z",
     "iopub.status.idle": "2022-11-16T21:55:54.096866Z",
     "shell.execute_reply": "2022-11-16T21:55:54.095511Z",
     "shell.execute_reply.started": "2022-11-16T21:55:53.943713Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def naive(train, test, param):\n",
    "    \n",
    "    best = []   # Lista do Melhor Resultado\n",
    "    timeList = [] # Lista do Tempo de Treinamento de cada Modelo\n",
    "    resul = [] # Lista de Todas informações na lista de Objetos\n",
    "    \n",
    "    start_time_total =  time.time()\n",
    "  \n",
    "    for x in param.smoothing:\n",
    "            \n",
    "        start_time =  time.time()\n",
    "        \n",
    "        # Define o Modelo \n",
    "        trainer = NaiveBayes(smoothing=x, modelType=\"multinomial\")    \n",
    "        evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\\\n",
    "                metricName=\"accuracy\")\n",
    "        \n",
    "        # Realiza o Treinamento e Calcula Acuracia\n",
    "        model = trainer.fit(train)\n",
    "        result_nb = model.transform(test)\n",
    "        accuracy_nb = evaluator.evaluate(result_nb) * 100\n",
    "             \n",
    "        timeFinal = time.time() - start_time\n",
    "        timeList.append(timeFinal)\n",
    "        \n",
    "        print(\"Algorithm: Naive Bayes | Accuracy = %3.1f %% | Time = %3.1f s | Smoothing = %3.1f\" % (accuracy_nb, timeFinal, x))\n",
    "    \n",
    "        # Matriz de Confusão\n",
    "        preds_and_labels = result_nb.select(['prediction','label']).withColumn('label', F.col('label').cast(FloatType())).orderBy('prediction')\n",
    "        preds_and_labels = preds_and_labels.select(['prediction','label'])\n",
    "        metrics = MulticlassMetrics(preds_and_labels.rdd.map(tuple))\n",
    "        \n",
    "        \n",
    "        prec = metrics.precision(1.0) *100\n",
    "        fp = metrics.falsePositiveRate(1.0)*100\n",
    "        rec =  metrics.recall(1.0)*100\n",
    "        \n",
    "        resul.append(Resultados('naive', accuracy_nb, timeFinal, prec, fp, rec, x, None))\n",
    "        \n",
    "        best.append(accuracy_nb)\n",
    "    \n",
    "    \n",
    "    timeTotal = time.time() - start_time_total\n",
    "\n",
    "    print(\"Tempo Médio: %3.1f s\" % (sum(timeList)/len(timeList)))\n",
    "    print(\"Tempo Total: %3.1f s\" % timeTotal)\n",
    "  \n",
    "    return resul\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T21:55:54.099487Z",
     "iopub.status.busy": "2022-11-16T21:55:54.099096Z",
     "iopub.status.idle": "2022-11-16T21:55:54.212687Z",
     "shell.execute_reply": "2022-11-16T21:55:54.211150Z",
     "shell.execute_reply.started": "2022-11-16T21:55:54.099442Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def svm(train, test, param):\n",
    "    \n",
    "    best = []\n",
    "\n",
    "    timeList = []\n",
    "\n",
    "    resul = []\n",
    "\n",
    "    start_time_total =  time.time()\n",
    "    \n",
    "    for x in param.maxIter:\n",
    "        for y in param.regParam:\n",
    "            \n",
    "            start_time =  time.time()\n",
    "\n",
    "    \n",
    "            trainer = LinearSVC(featuresCol='features', labelCol='label',\\\n",
    "                            maxIter=x, regParam=y)\n",
    "\n",
    "            ovr_trainer = OneVsRest(classifier=trainer)\n",
    "\n",
    "\n",
    "            model = ovr_trainer.fit(train)\n",
    "\n",
    "            result_svm = model.transform(test)\n",
    "\n",
    "\n",
    "            evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\\\n",
    "                    metricName=\"accuracy\")\n",
    "\n",
    "            accuracy_svm = evaluator.evaluate(result_svm) * 100\n",
    "            \n",
    "            timeFinal = time.time() - start_time\n",
    "\n",
    "            timeList.append(timeFinal)\n",
    "\n",
    "            print(\"Algorithm: SVM | Accuracy = %3.1f %% | Time = %3.1f s | maxIter = %3.1f | regParam = %3.1f\" % (accuracy_svm, timeFinal, x, y))\n",
    "\n",
    "            # Matriz de Confusão\n",
    "            preds_and_labels = result_svm.select(['prediction','label']).withColumn('label', F.col('label').cast(FloatType())).orderBy('prediction')\n",
    "            preds_and_labels = preds_and_labels.select(['prediction','label'])\n",
    "            metrics = MulticlassMetrics(preds_and_labels.rdd.map(tuple))\n",
    "        \n",
    "        \n",
    "            prec = metrics.precision(1.0) *100\n",
    "            fp = metrics.falsePositiveRate(1.0)*100\n",
    "            rec =  metrics.recall(1.0) *100\n",
    "            \n",
    "            \n",
    "            resul.append(Resultados('svm', accuracy_svm, timeFinal, prec, fp, rec, x, y))\n",
    "\n",
    "            \n",
    "            best.append(accuracy_svm)\n",
    "    \n",
    "    timeTotal = time.time() - start_time_total\n",
    "            \n",
    "    print(\"Tempo Médio: %3.1f s\" % (sum(timeList)/len(timeList)))\n",
    "    print(\"Tempo Total: %3.1f s\" % timeTotal)\n",
    "\n",
    "\n",
    "\n",
    "#    return max(best)\n",
    "    return resul\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T21:55:54.215790Z",
     "iopub.status.busy": "2022-11-16T21:55:54.215281Z",
     "iopub.status.idle": "2022-11-16T21:55:54.314618Z",
     "shell.execute_reply": "2022-11-16T21:55:54.313081Z",
     "shell.execute_reply.started": "2022-11-16T21:55:54.215731Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decTree(train, test, param):\n",
    "    \n",
    "    best = [] # Lista do Melhor Resultado\n",
    "    timeList = [] # Lista do Tempo de Treinamento de cada Modelo\n",
    "    resul = [] # Lista de Todas informações na lista de Objetos\n",
    "\n",
    "    start_time_total =  time.time()\n",
    "    \n",
    "    for x in param.maxDepth:\n",
    "        for y in param.maxBin:\n",
    "            \n",
    "            start_time =  time.time()\n",
    "            \n",
    "            # Define o Modelo \n",
    "            trainer = DecisionTreeClassifier(featuresCol='features', labelCol='label', predictionCol='prediction', probabilityCol='probability',\\\n",
    "                                             rawPredictionCol='rawPrediction', maxDepth=x, maxBins=y,\\\n",
    "                                             maxMemoryInMB=1024, cacheNodeIds=False, impurity='gini')\n",
    "\n",
    "\n",
    "            evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\\\n",
    "                        metricName=\"accuracy\")\n",
    "\n",
    "            # Realiza o Treinamento e Calcula Acuracia\n",
    "            model = trainer.fit(train)\n",
    "            result_dt = model.transform(test)\n",
    "            accuracy_dt = evaluator.evaluate(result_dt) * 100\n",
    "        \n",
    "            timeFinal = time.time() - start_time\n",
    "            \n",
    "            timeList.append(timeFinal)\n",
    "        \n",
    "            print(\"Algorithm: decTree | Accuracy = %3.1f %% | Time = %3.1f s | maxDepth = %3.1f | maxBin = %3.1f\" % (accuracy_dt, timeFinal, x, y))\n",
    "\n",
    "            # Matriz de Confusão\n",
    "            preds_and_labels = result_dt.select(['prediction','label']).withColumn('label', F.col('label').cast(FloatType())).orderBy('prediction')\n",
    "            preds_and_labels = preds_and_labels.select(['prediction','label'])\n",
    "            metrics = MulticlassMetrics(preds_and_labels.rdd.map(tuple))\n",
    "        \n",
    "            prec = metrics.precision(1.0) *100\n",
    "            fp = metrics.falsePositiveRate(1.0)*100\n",
    "            rec =  metrics.recall(1.0) *100  \n",
    "            \n",
    "            resul.append(Resultados('dtree', accuracy_dt, timeFinal, prec, fp, rec, x, y))\n",
    "            \n",
    "            best.append(accuracy_dt)\n",
    "    \n",
    "    timeTotal = time.time() - start_time_total\n",
    "            \n",
    "    print(\"Tempo Médio: %3.1f s\" % (sum(timeList)/len(timeList)))\n",
    "    print(\"Tempo Total: %3.1f s\" % timeTotal)\n",
    "    \n",
    "    return resul\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função que Executa Todos os Algoritmos de ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T21:55:54.316951Z",
     "iopub.status.busy": "2022-11-16T21:55:54.316673Z",
     "iopub.status.idle": "2022-11-16T21:55:54.422001Z",
     "shell.execute_reply": "2022-11-16T21:55:54.420080Z",
     "shell.execute_reply.started": "2022-11-16T21:55:54.316919Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def autoChoice(train, test, choice, naivep, svmp, dtreep):\n",
    "    \n",
    "    resul=[]\n",
    "    \n",
    "    \n",
    "    if choice == 'auto':\n",
    "        resul.append(Resultados('naive' ,naive(train, test, naivep)))\n",
    "        resul.append(Resultados('svm', svm(train, test, svmp)))\n",
    "        resul.append(Resultados('DecisionTree', decTree(train, test, dtreep)))\n",
    "        \n",
    "        resul.sort(key=lambda x: x.acuracia, reverse=True)\n",
    "        print(resul[0].algoritmo, resul[0].acuracia, sep =' ' )\n",
    "        \n",
    "        \n",
    "        \n",
    "    elif choice == 'naive':\n",
    "        return naive(train, test, naivep)\n",
    "        #print(\"A acurácia da Naive Bayes: %3.1f %%\" % naive(train, test, naivep))\n",
    "    elif choice == 'svm':\n",
    "        return svm(train, test, svmp)\n",
    "        #print(\"A acurácia da SVM: %3.1f %%\" % svm(train, test, svmp))\n",
    "    elif choice == 'tree':\n",
    "        return decTree(train, test, dtreep)\n",
    "        #print(\"A acurácia da Decision Tree: %3.1f %%\" % decTree(train, test, dtreep))\n",
    "    else:\n",
    "        print(\"Opção Inválida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função que Gera o Gráfico 2D (Apenas para Naive Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T21:55:54.425105Z",
     "iopub.status.busy": "2022-11-16T21:55:54.424594Z",
     "iopub.status.idle": "2022-11-16T21:55:54.499520Z",
     "shell.execute_reply": "2022-11-16T21:55:54.497923Z",
     "shell.execute_reply.started": "2022-11-16T21:55:54.425045Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def graphic_2d_naive(resul):\n",
    "\n",
    "    x=[]\n",
    "    y=[]\n",
    "\n",
    "    for i in range(0,len(resul)):\n",
    "        y.append(resul[i].acuracia)\n",
    "        x.append(resul[i].parametroA)\n",
    "\n",
    "\n",
    "    x = np.array(x)\n",
    "    #x = range(0,len(resul))\n",
    "    y = np.array(y)\n",
    "\n",
    "    #print(y)\n",
    "    \n",
    "    df=pd.DataFrame({'Smoothing': x, 'Accuracy %': y })\n",
    "\n",
    "    # Draw line chart with dashed line\n",
    "    plt.plot( 'Smoothing', 'Accuracy %', data=df, linestyle='solid')\n",
    "\n",
    "    plt.title(\"Iris Dataset\", loc=\"left\", fontsize=20)\n",
    "    plt.xlabel(\"Smoothing\", fontsize=16)\n",
    "    plt.ylabel(\"Accuracy %\", fontsize=16)\n",
    "    plt.savefig(\"/home/tiago.linhares/Dissertacao/figura-5.png\")\n",
    "\n",
    "    # Show graph\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função que Gera o Gráfico 3D (Para SVM e Decision Tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de Gráfico Ajustado para SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T21:55:54.502800Z",
     "iopub.status.busy": "2022-11-16T21:55:54.501988Z",
     "iopub.status.idle": "2022-11-16T21:55:54.574738Z",
     "shell.execute_reply": "2022-11-16T21:55:54.573187Z",
     "shell.execute_reply.started": "2022-11-16T21:55:54.502737Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def graphic_3d_svm(resul):\n",
    "\n",
    "    x=[]\n",
    "    y=[]\n",
    "    z=[]\n",
    "\n",
    "    for i in range(0,len(resul)):\n",
    "        y.append(resul[i].parametroA)\n",
    "        x.append(resul[i].parametroB)\n",
    "        z.append(resul[i].acuracia)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca(projection='3d')\n",
    "    #ax.set_title('Glass Dataset', fontsize=20)\n",
    "    #ax.set_title('Ionosphere Dataset', fontsize=20)\n",
    "    #ax.set_title('Mammographic Masses Dataset', fontsize=20)\n",
    "    ax.set_title('Libras Dataset', fontsize=20)\n",
    "    ax.set_xlabel('RegParam', fontsize=16)\n",
    "    ax.set_ylabel('MaxIter', fontsize=16)\n",
    "    ax.set_zlabel('Accuracy %', fontsize=16)\n",
    "    surf = ax.plot_trisurf(x, y, z, cmap=plt.cm.magma, linewidth=0.2)\n",
    "    fig.colorbar( surf, shrink=0.5, aspect=5, pad = 0.15)\n",
    "    #fig.savefig(\"figura-10.png\")  # glass\n",
    "    #fig.savefig(\"figura-11.png\") # ionosphere\n",
    "    #fig.savefig(\"figura-12.png\") # mammographic_masses\n",
    "    #fig.savefig(\"figura-13.png\") # libras\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de Gráfico Ajustado para Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T21:55:54.577707Z",
     "iopub.status.busy": "2022-11-16T21:55:54.577073Z",
     "iopub.status.idle": "2022-11-16T21:55:54.681099Z",
     "shell.execute_reply": "2022-11-16T21:55:54.679598Z",
     "shell.execute_reply.started": "2022-11-16T21:55:54.577666Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def graphic_3d_tree(resul):\n",
    "\n",
    "    x=[]\n",
    "    y=[]\n",
    "    z=[]\n",
    "\n",
    "    for i in range(0,len(resul)):\n",
    "        x.append(resul[i].parametroA)\n",
    "        y.append(resul[i].parametroB)\n",
    "        z.append(resul[i].acuracia)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca(projection='3d')\n",
    "    #ax.set_title('WineQuality-White Dataset', fontsize=20) #figura-8\n",
    "    ax.set_title('WineQuality-Red Dataset', fontsize=20)  #figura-9\n",
    "\n",
    "    ax.set_xlabel('maxDepth', fontsize=16)\n",
    "    ax.set_ylabel('maxBin', fontsize=16)\n",
    "    ax.set_zlabel('Accuracy %', fontsize=16)\n",
    "    surf = ax.plot_trisurf(x, y, z, cmap=plt.cm.plasma, linewidth=0.2)\n",
    "    fig.colorbar( surf, shrink=0.5, aspect=5, pad = 0.15)\n",
    "    #fig.savefig(\"figura-8.png\")\n",
    "    fig.savefig(\"figura-9.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T21:55:54.684271Z",
     "iopub.status.busy": "2022-11-16T21:55:54.683630Z",
     "iopub.status.idle": "2022-11-16T21:55:59.201437Z",
     "shell.execute_reply": "2022-11-16T21:55:59.200181Z",
     "shell.execute_reply.started": "2022-11-16T21:55:54.684167Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Datasets Marcados com \"OK\", são os que já estão tratados e testados\n",
    "\n",
    "########################################################################################\n",
    "                                    #NAIVE BAYES\n",
    "\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').\\\n",
    "#            load('dataset/iris.data')#OK # Varia # Acuracia Maxima: 98%\n",
    "\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').\\\n",
    "#            load('dataset/glass.data') # OK # Varia # Acuracia Maxima: 80.5\n",
    "\n",
    "orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').\\\n",
    "            load('dataset/sonar.data')#OK # Varia # Acuracia Maxima: 77.8\n",
    "\n",
    "########################################################################################\n",
    "\n",
    "\n",
    "########################################################################################\n",
    "                                    #Decision Tree\n",
    "\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').load('dataset/wine-red.data')\n",
    "# ESSE É WHITE: Accuracy = 62.2 %\n",
    "# Tempo Total Com Distribuição: 462.5 s\n",
    "# Tempo Total Sem Distribuição: 1365.0 s\n",
    "\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').load('dataset/wine-white.data')\n",
    "# ESSE É RED: Accuracy = 58.6 %\n",
    "# Tempo Total Com Distribuicao: 820.7 s\n",
    "# Tempo Total Sem Distribuição: 2009.8 s\n",
    "\n",
    "\n",
    "########################################################################################\n",
    "\n",
    "########################################################################################\n",
    "                                    #SVM\n",
    "# Glass\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').load('dataset/glass.data') \n",
    "# Accuracy = 76.6 % / Tempo Total Com distribuição: 1353.1 s / Tempo Total Sem distribuição: 3441.9 s\n",
    "\n",
    "# Ionosphere\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').load('dataset/ionosphere.data') \n",
    "# Accuracy = 89.9 % / Tempo Total Com Distribuição: 256.7 s / Tempo Total Sem distribuição: 638.2\n",
    "\n",
    "# Mammographic\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').load('dataset/mammographic_masses.data') \n",
    "# Accuracy = 84.1 % / Tempo Total Com Distribuição: 346.7 s / Tempo Total Sem distribuição: 753.4\n",
    "\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').load('dataset/libras.data') \n",
    "# Accuracy = 64.0 % / Tempo Total Com Distribuição: 2641.9 s / Tempo Total Sem distribuição: 6328.5\n",
    "\n",
    "########################################################################################\n",
    "\n",
    "\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').\\\n",
    "#            load('dataset/breast-cancer-wisconsin.data')#OK # Estatico\n",
    "\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').\\\n",
    "#            load('dataset/lymphography.data')#OK # Estatico\n",
    "\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').\\\n",
    "#            load('dataset/balance-scale.data')#OK # Estatico\n",
    "\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').\\\n",
    "#            load('dataset/balance-scale2.data')#OK # Estatico\n",
    "\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').\\\n",
    "#            load('dataset/ecoli.data')#\n",
    "\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').\\\n",
    "#            load('dataset/yeast.data')#\n",
    "\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').\\\n",
    "#            load('dataset/wine-white.data')#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T21:55:59.206783Z",
     "iopub.status.busy": "2022-11-16T21:55:59.206276Z",
     "iopub.status.idle": "2022-11-16T21:55:59.216478Z",
     "shell.execute_reply": "2022-11-16T21:55:59.215783Z",
     "shell.execute_reply.started": "2022-11-16T21:55:59.206724Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_sample = 0.7\n",
    "test_sample = 0.3\n",
    "\n",
    "# 'auto'  = Testa tudo\n",
    "# 'tree'  = Decision Tree\n",
    "# 'naive' = Naive Bayes\n",
    "# 'svm'   = SVM\n",
    "choice = 'naive'\n",
    "\n",
    "# Parâmetros Naive\n",
    "# Nome = Smoothing\n",
    "#smoothing = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "smoothing = [round(x * 0.1, 1) for x in range(0, 100)]\n",
    "naiveParam = Naive(smoothing)\n",
    "\n",
    "# Parâmetros SVM\n",
    "maxIter = [90,100,110,120,130]\n",
    "regParam = [0.0,0.5,1.0]\n",
    "svmParam = SVM(maxIter, regParam)\n",
    "\n",
    "# Parâmetros Decision Tree\n",
    "# Deapht / MaxIter\n",
    "maxDepth = [x for x in range(1, 31)] # 31 é o máximo\n",
    "maxBin = [32,64,128,256,512,1024]\n",
    "dtreeParam = Tree(maxDepth, maxBin)\n",
    "\n",
    "################\n",
    "\n",
    "\n",
    "#amostra = \"\"\n",
    "#execucao = \"dtree-MD-custom-30-40-CP-custom-15-30\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-Processamento/Tratamento Padrão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T21:55:59.218459Z",
     "iopub.status.busy": "2022-11-16T21:55:59.217576Z",
     "iopub.status.idle": "2022-11-16T21:56:00.516158Z",
     "shell.execute_reply": "2022-11-16T21:56:00.514555Z",
     "shell.execute_reply.started": "2022-11-16T21:55:59.218425Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol=\"class\", outputCol=\"label\").fit(orig_data)\n",
    "label_data = indexer.transform(orig_data)\n",
    "\n",
    "labelReverse = IndexToString().setInputCol(\"label\")\n",
    "\n",
    "label_data = label_data.drop(\"class\")\n",
    "\n",
    "ignore = ['label']\n",
    "list = [x for x in label_data.columns if x not in ignore]\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "            inputCols=list,\n",
    "            outputCol='features')\n",
    "\n",
    "data = (assembler.transform(label_data).select(\"label\",\"features\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomSplit Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T21:56:00.519632Z",
     "iopub.status.busy": "2022-11-16T21:56:00.518414Z",
     "iopub.status.idle": "2022-11-16T21:56:00.548670Z",
     "shell.execute_reply": "2022-11-16T21:56:00.547277Z",
     "shell.execute_reply.started": "2022-11-16T21:56:00.519560Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "(train, test) = data.randomSplit([train_sample, test_sample], 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T21:56:00.551961Z",
     "iopub.status.busy": "2022-11-16T21:56:00.551050Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/16 18:56:01 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "Algorithm: Naive Bayes | Accuracy = 72.2 % | Time = 2.0 s | Smoothing = 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pyspark/sql/context.py:157: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: Naive Bayes | Accuracy = 72.2 % | Time = 0.7 s | Smoothing = 0.1\n",
      "Algorithm: Naive Bayes | Accuracy = 72.2 % | Time = 0.7 s | Smoothing = 0.2\n",
      "Algorithm: Naive Bayes | Accuracy = 73.6 % | Time = 0.7 s | Smoothing = 0.3\n",
      "Algorithm: Naive Bayes | Accuracy = 73.6 % | Time = 0.6 s | Smoothing = 0.4\n",
      "Algorithm: Naive Bayes | Accuracy = 73.6 % | Time = 0.6 s | Smoothing = 0.5\n",
      "Algorithm: Naive Bayes | Accuracy = 73.6 % | Time = 0.5 s | Smoothing = 0.6\n",
      "Algorithm: Naive Bayes | Accuracy = 73.6 % | Time = 0.5 s | Smoothing = 0.7\n",
      "Algorithm: Naive Bayes | Accuracy = 73.6 % | Time = 0.5 s | Smoothing = 0.8\n",
      "Algorithm: Naive Bayes | Accuracy = 73.6 % | Time = 0.5 s | Smoothing = 0.9\n",
      "Algorithm: Naive Bayes | Accuracy = 75.0 % | Time = 0.5 s | Smoothing = 1.0\n",
      "Algorithm: Naive Bayes | Accuracy = 75.0 % | Time = 0.5 s | Smoothing = 1.1\n",
      "Algorithm: Naive Bayes | Accuracy = 76.4 % | Time = 0.5 s | Smoothing = 1.2\n",
      "Algorithm: Naive Bayes | Accuracy = 76.4 % | Time = 0.6 s | Smoothing = 1.3\n",
      "Algorithm: Naive Bayes | Accuracy = 76.4 % | Time = 0.7 s | Smoothing = 1.4\n",
      "Algorithm: Naive Bayes | Accuracy = 76.4 % | Time = 0.5 s | Smoothing = 1.5\n",
      "Algorithm: Naive Bayes | Accuracy = 76.4 % | Time = 0.5 s | Smoothing = 1.6\n",
      "Algorithm: Naive Bayes | Accuracy = 76.4 % | Time = 0.5 s | Smoothing = 1.7\n",
      "Algorithm: Naive Bayes | Accuracy = 76.4 % | Time = 0.5 s | Smoothing = 1.8\n",
      "Algorithm: Naive Bayes | Accuracy = 76.4 % | Time = 0.5 s | Smoothing = 1.9\n",
      "Algorithm: Naive Bayes | Accuracy = 76.4 % | Time = 0.5 s | Smoothing = 2.0\n",
      "Algorithm: Naive Bayes | Accuracy = 76.4 % | Time = 0.4 s | Smoothing = 2.1\n",
      "Algorithm: Naive Bayes | Accuracy = 76.4 % | Time = 0.5 s | Smoothing = 2.2\n",
      "Algorithm: Naive Bayes | Accuracy = 76.4 % | Time = 0.6 s | Smoothing = 2.3\n",
      "Algorithm: Naive Bayes | Accuracy = 76.4 % | Time = 0.5 s | Smoothing = 2.4\n",
      "Algorithm: Naive Bayes | Accuracy = 76.4 % | Time = 0.4 s | Smoothing = 2.5\n",
      "Algorithm: Naive Bayes | Accuracy = 76.4 % | Time = 0.4 s | Smoothing = 2.6\n",
      "Algorithm: Naive Bayes | Accuracy = 76.4 % | Time = 0.4 s | Smoothing = 2.7\n",
      "Algorithm: Naive Bayes | Accuracy = 77.8 % | Time = 0.5 s | Smoothing = 2.8\n"
     ]
    }
   ],
   "source": [
    "resul = []\n",
    "resul = autoChoice(train, test, choice, naiveParam, svmParam, dtreeParam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#graphic_2d_naive(resul)\n",
    "#graphic_3d_tree(resul)\n",
    "#graphic_3d_svm(resul)\n",
    "\n",
    "if choice == 'naive':\n",
    "    graphic_2d_naive(resul)\n",
    "elif choice == 'svm':\n",
    "    graphic_3d_svm(resul)\n",
    "elif choice == 'tree':\n",
    "    graphic_3d_tree(resul)\n",
    "else:\n",
    "    print(\"Opção Inválida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Exibe os Melhores Resultados em Ordem Decrescente\n",
    "resul.sort(key=lambda x: x.acuracia, reverse=True)\n",
    "for i in range(5):\n",
    "    if(resul[i].parametroB!=None):\n",
    "        print(\"Algorithm: %s | Accuracy = %3.1f %% | Time = %3.1f s | ParametroA = %3.1f | ParametroB = %3.1f\" % (resul[i].algoritmo, resul[i].acuracia, resul[i].tempo, resul[i].parametroA, resul[i].parametroB))\n",
    "    else:\n",
    "        print(\"Algorithm: %s | Accuracy = %3.1f %% | Time = %3.1f s | ParametroA = %3.1f\" % (resul[i].algoritmo, resul[i].acuracia, resul[i].tempo, resul[i].parametroA))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime Outros Resultados do Melhor Modelo\n",
    "print(\"Algorithm: %s | Precisão = %3.1f %% | False Positive = %3.1f %% | Recall = %3.1f %%\" % (resul[0].algoritmo, resul[0].precisao, resul[0].fpositivos, resul[0].recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
