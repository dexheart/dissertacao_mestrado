{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit-Spark Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Spark Lib\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.util import MLUtils\n",
    "\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer, IndexToString\n",
    "from pyspark.ml.feature import VectorAssembler, VectorIndexer\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import LinearSVC, OneVsRest\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.mllib.util import MLUtils\n",
    "\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .appName(\"FitSpark\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Resultados:\n",
    "    def __init__(self, algoritmo, acuracia, tempo, precisao, fpositivos, recall, parametroA, parametroB):\n",
    "        self.algoritmo = algoritmo \n",
    "        self.acuracia = acuracia\n",
    "        self.tempo = tempo\n",
    "        self.precisao = precisao\n",
    "        self.fpositivos = fpositivos\n",
    "        self.recall = recall\n",
    "        self.parametroA = parametroA\n",
    "        self.parametroB = parametroB\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "class Naive:\n",
    "    def __init__(self, smoothing):\n",
    "        self.smoothing = smoothing \n",
    "        \n",
    "class SVM:\n",
    "    def __init__(self, maxIter, regParam):\n",
    "        self.maxIter = maxIter \n",
    "        self.regParam = regParam\n",
    "        \n",
    "class Tree:\n",
    "    def __init__(self, maxDepth, maxBin):\n",
    "        self.maxDepth = maxDepth \n",
    "        self.maxBin = maxBin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def naive(train, test, param):\n",
    "    \n",
    "    best = []   # Lista do Melhor Resultado\n",
    "    timeList = [] # Lista do Tempo de Treinamento de cada Modelo\n",
    "    resul = [] # Lista de Todas informações na lista de Objetos\n",
    "    \n",
    "    start_time_total =  time.time()\n",
    "  \n",
    "    for x in param.smoothing:\n",
    "            \n",
    "        start_time =  time.time()\n",
    "        \n",
    "        # Define o Modelo \n",
    "        trainer = NaiveBayes(smoothing=x, modelType=\"multinomial\")    \n",
    "        evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\\\n",
    "                metricName=\"accuracy\")\n",
    "        \n",
    "        # Realiza o Treinamento e Calcula Acuracia\n",
    "        model = trainer.fit(train)\n",
    "        result_nb = model.transform(test)\n",
    "        accuracy_nb = evaluator.evaluate(result_nb) * 100\n",
    "             \n",
    "        timeFinal = time.time() - start_time\n",
    "        timeList.append(timeFinal)\n",
    "        \n",
    "        print(\"Algorithm: Naive Bayes | Accuracy = %3.1f %% | Time = %3.1f s | Smoothing = %3.1f\" % (accuracy_nb, timeFinal, x))\n",
    "    \n",
    "        # Matriz de Confusão\n",
    "        preds_and_labels = result_nb.select(['prediction','label']).withColumn('label', F.col('label').cast(FloatType())).orderBy('prediction')\n",
    "        preds_and_labels = preds_and_labels.select(['prediction','label'])\n",
    "        metrics = MulticlassMetrics(preds_and_labels.rdd.map(tuple))\n",
    "        \n",
    "        \n",
    "        prec = metrics.precision(1.0) *100\n",
    "        fp = metrics.falsePositiveRate(1.0)*100\n",
    "        rec =  metrics.recall(1.0)*100\n",
    "        \n",
    "        resul.append(Resultados('naive', accuracy_nb, timeFinal, prec, fp, rec, x, None))\n",
    "        \n",
    "        best.append(accuracy_nb)\n",
    "    \n",
    "    \n",
    "    timeTotal = time.time() - start_time_total\n",
    "\n",
    "    print(\"Tempo Médio: %3.1f s\" % (sum(timeList)/len(timeList)))\n",
    "    print(\"Tempo Total: %3.1f s\" % timeTotal)\n",
    "  \n",
    "    return resul\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def svm(train, test, param):\n",
    "    \n",
    "    best = []\n",
    "\n",
    "    timeList = []\n",
    "\n",
    "    resul = []\n",
    "\n",
    "    start_time_total =  time.time()\n",
    "    \n",
    "    for x in param.maxIter:\n",
    "        for y in param.regParam:\n",
    "            \n",
    "            start_time =  time.time()\n",
    "\n",
    "    \n",
    "            trainer = LinearSVC(featuresCol='features', labelCol='label',\\\n",
    "                            maxIter=x, regParam=y)\n",
    "\n",
    "            ovr_trainer = OneVsRest(classifier=trainer)\n",
    "\n",
    "\n",
    "            model = ovr_trainer.fit(train)\n",
    "\n",
    "            result_svm = model.transform(test)\n",
    "\n",
    "\n",
    "            evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\\\n",
    "                    metricName=\"accuracy\")\n",
    "\n",
    "            accuracy_svm = evaluator.evaluate(result_svm) * 100\n",
    "            \n",
    "            timeFinal = time.time() - start_time\n",
    "\n",
    "            timeList.append(timeFinal)\n",
    "\n",
    "            print(\"Algorithm: SVM | Accuracy = %3.1f %% | Time = %3.1f s | maxIter = %3.1f | regParam = %3.1f\" % (accuracy_svm, timeFinal, x, y))\n",
    "\n",
    "            # Matriz de Confusão\n",
    "            preds_and_labels = result_svm.select(['prediction','label']).withColumn('label', F.col('label').cast(FloatType())).orderBy('prediction')\n",
    "            preds_and_labels = preds_and_labels.select(['prediction','label'])\n",
    "            metrics = MulticlassMetrics(preds_and_labels.rdd.map(tuple))\n",
    "        \n",
    "        \n",
    "            prec = metrics.precision(1.0) *100\n",
    "            fp = metrics.falsePositiveRate(1.0)*100\n",
    "            rec =  metrics.recall(1.0) *100\n",
    "            \n",
    "            \n",
    "            resul.append(Resultados('svm', accuracy_svm, timeFinal, prec, fp, rec, x, y))\n",
    "\n",
    "            \n",
    "            best.append(accuracy_svm)\n",
    "    \n",
    "    timeTotal = time.time() - start_time_total\n",
    "            \n",
    "    print(\"Tempo Médio: %3.1f s\" % (sum(timeList)/len(timeList)))\n",
    "    print(\"Tempo Total: %3.1f s\" % timeTotal)\n",
    "\n",
    "\n",
    "\n",
    "#    return max(best)\n",
    "    return resul\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decTree(train, test, param):\n",
    "    \n",
    "    best = [] # Lista do Melhor Resultado\n",
    "    timeList = [] # Lista do Tempo de Treinamento de cada Modelo\n",
    "    resul = [] # Lista de Todas informações na lista de Objetos\n",
    "\n",
    "    start_time_total =  time.time()\n",
    "    \n",
    "    for x in param.maxDepth:\n",
    "        for y in param.maxBin:\n",
    "            \n",
    "            start_time =  time.time()\n",
    "            \n",
    "            # Define o Modelo \n",
    "            trainer = DecisionTreeClassifier(featuresCol='features', labelCol='label', predictionCol='prediction', probabilityCol='probability',\\\n",
    "                                             rawPredictionCol='rawPrediction', maxDepth=x, maxBins=y,\\\n",
    "                                             maxMemoryInMB=1024, cacheNodeIds=False, impurity='gini')\n",
    "\n",
    "\n",
    "            evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\\\n",
    "                        metricName=\"accuracy\")\n",
    "\n",
    "            # Realiza o Treinamento e Calcula Acuracia\n",
    "            model = trainer.fit(train)\n",
    "            result_dt = model.transform(test)\n",
    "            accuracy_dt = evaluator.evaluate(result_dt) * 100\n",
    "        \n",
    "            timeFinal = time.time() - start_time\n",
    "            \n",
    "            timeList.append(timeFinal)\n",
    "        \n",
    "            print(\"Algorithm: decTree | Accuracy = %3.1f %% | Time = %3.1f s | maxDepth = %3.1f | maxBin = %3.1f\" % (accuracy_dt, timeFinal, x, y))\n",
    "\n",
    "            # Matriz de Confusão\n",
    "            preds_and_labels = result_dt.select(['prediction','label']).withColumn('label', F.col('label').cast(FloatType())).orderBy('prediction')\n",
    "            preds_and_labels = preds_and_labels.select(['prediction','label'])\n",
    "            metrics = MulticlassMetrics(preds_and_labels.rdd.map(tuple))\n",
    "        \n",
    "            prec = metrics.precision(1.0) *100\n",
    "            fp = metrics.falsePositiveRate(1.0)*100\n",
    "            rec =  metrics.recall(1.0) *100  \n",
    "            \n",
    "            resul.append(Resultados('dtree', accuracy_dt, timeFinal, prec, fp, rec, x, y))\n",
    "            \n",
    "            best.append(accuracy_dt)\n",
    "    \n",
    "    timeTotal = time.time() - start_time_total\n",
    "            \n",
    "    print(\"Tempo Médio: %3.1f s\" % (sum(timeList)/len(timeList)))\n",
    "    print(\"Tempo Total: %3.1f s\" % timeTotal)\n",
    "    \n",
    "    return resul\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função que Executa Todos os Algoritmos de ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def autoChoice(train, test, choice, naivep, svmp, dtreep):\n",
    "    \n",
    "    resul=[]\n",
    "    \n",
    "    \n",
    "    if choice == 'auto':\n",
    "        resul.append(Resultados('naive' ,naive(train, test, naivep)))\n",
    "        resul.append(Resultados('svm', svm(train, test, svmp)))\n",
    "        resul.append(Resultados('DecisionTree', decTree(train, test, dtreep)))\n",
    "        \n",
    "        resul.sort(key=lambda x: x.acuracia, reverse=True)\n",
    "        print(resul[0].algoritmo, resul[0].acuracia, sep =' ' )\n",
    "        \n",
    "        \n",
    "        \n",
    "    elif choice == 'naive':\n",
    "        return naive(train, test, naivep)\n",
    "        #print(\"A acurácia da Naive Bayes: %3.1f %%\" % naive(train, test, naivep))\n",
    "    elif choice == 'svm':\n",
    "        return svm(train, test, svmp)\n",
    "        #print(\"A acurácia da SVM: %3.1f %%\" % svm(train, test, svmp))\n",
    "    elif choice == 'tree':\n",
    "        return decTree(train, test, dtreep)\n",
    "        #print(\"A acurácia da Decision Tree: %3.1f %%\" % decTree(train, test, dtreep))\n",
    "    else:\n",
    "        print(\"Opção Inválida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função que Gera o Gráfico 2D (Apenas para Naive Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def graphic_2d(resul):\n",
    "\n",
    "    x=[]\n",
    "    y=[]\n",
    "\n",
    "    for i in range(0,len(resul)):\n",
    "        y.append(resul[i].acuracia)\n",
    "        x.append(resul[i].parametroA)\n",
    "\n",
    "\n",
    "    x = np.array(x)\n",
    "    #x = range(0,len(resul))\n",
    "    y = np.array(y)\n",
    "\n",
    "    #print(y)\n",
    "    \n",
    "    df=pd.DataFrame({'Smoothing': x, 'Accuracy %': y })\n",
    "\n",
    "    # Draw line chart with dashed line\n",
    "    plt.plot( 'Smoothing', 'Accuracy %', data=df, linestyle='solid')\n",
    "\n",
    "    plt.title(\"Iris Dataset\", loc=\"left\", fontsize=20)\n",
    "    plt.xlabel(\"Smoothing\", fontsize=16)\n",
    "    plt.ylabel(\"Accuracy %\", fontsize=16)\n",
    "    plt.savefig(\"figura-5.png\")\n",
    "\n",
    "    # Show graph\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função que Gera o Gráfico 3D (Para SVM e Decision Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def graphic_3d(resul):\n",
    "\n",
    "    x=[]\n",
    "    y=[]\n",
    "    z=[]\n",
    "\n",
    "    for i in range(0,len(resul)):\n",
    "        x.append(resul[i].parametroA)\n",
    "        y.append(resul[i].parametroB)\n",
    "        z.append(resul[i].acuracia)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca(projection='3d')\n",
    "    ax.set_title('WineQuality-Red Dataset', fontsize=20)\n",
    "    ax.set_xlabel('MaxDepth', fontsize=16)\n",
    "    ax.set_ylabel('MaxBin', fontsize=16)\n",
    "    ax.set_zlabel('Accuracy %', fontsize=16)\n",
    "    surf = ax.plot_trisurf(x, y, z, cmap=plt.cm.viridis, linewidth=0.2)\n",
    "    fig.colorbar( surf, shrink=0.5, aspect=5, loc=\"left\")\n",
    "    fig.savefig(\"figura-9.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Datasets Marcados com \"OK\", são os que já estão tratados e testados\n",
    "\n",
    "########################################################################################\n",
    "                                    #NAIVE BAYES\n",
    "\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').\\\n",
    "#            load('/home/tiago/Mestrado/Dissertacao/dataset/iris.data')#OK # Varia # Acuracia Maxima: 98%\n",
    "\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').\\\n",
    "#            load('/home/tiago/Mestrado/Dissertacao/dataset/glass.data') # OK # Varia # Acuracia Maxima: 80.5\n",
    "\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').\\\n",
    "#            load('/home/tiago/Mestrado/Dissertacao/dataset/sonar.data')#OK # Varia # Acuracia Maxima: 77.8\n",
    "\n",
    "########################################################################################\n",
    "\n",
    "\n",
    "########################################################################################\n",
    "                                    #Decision Tree\n",
    "\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').load('/home/tiago/Mestrado/Dissertacao/dataset/wine-red.data')\n",
    "# ESSE É WHITE: Accuracy = 62.2 %\n",
    "# Tempo Total Com Distribuição: 462.5 s\n",
    "# Tempo Total Sem Distribuição: 1365.0 s\n",
    "\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').load('/home/tiago/Mestrado/Dissertacao/dataset/wine-white.data')\n",
    "# ESSE É RED: Accuracy = 58.6 %\n",
    "# Tempo Total Com Distribuicao: 820.7 s\n",
    "# Tempo Total Sem Distribuição: 2009.8 s\n",
    "\n",
    "\n",
    "########################################################################################\n",
    "\n",
    "########################################################################################\n",
    "                                    #SVM\n",
    "\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').\\\n",
    "#            load('/home/tiago/Mestrado/Dissertacao/dataset/glass.data') \n",
    "\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').\\\n",
    "#            load('/home/tiago/Mestrado/Dissertacao/dataset/ionosphere.data') \n",
    "\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').\\\n",
    "#            load('/home/tiago/Mestrado/Dissertacao/dataset/mammographic_masses.data') \n",
    "\n",
    "orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').\\\n",
    "            load('/home/tiago/Mestrado/Dissertacao/dataset/libras.data') \n",
    "\n",
    "\n",
    "########################################################################################\n",
    "\n",
    "\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').\\\n",
    "#            load('/home/tiago/Mestrado/Dissertacao/dataset/breast-cancer-wisconsin.data')#OK # Estatico\n",
    "\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').\\\n",
    "#            load('/home/tiago/Mestrado/Dissertacao/dataset/lymphography.data')#OK # Estatico\n",
    "\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').\\\n",
    "#            load('/home/tiago/Mestrado/Dissertacao/dataset/balance-scale.data')#OK # Estatico\n",
    "\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').\\\n",
    "#            load('/home/tiago/Mestrado/Dissertacao/dataset/balance-scale2.data')#OK # Estatico\n",
    "\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').\\\n",
    "#            load('/home/tiago/Mestrado/Dissertacao/dataset/ecoli.data')#\n",
    "\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').\\\n",
    "#            load('/home/tiago/Mestrado/Dissertacao/dataset/yeast.data')#\n",
    "\n",
    "#orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').\\\n",
    "#            load('/home/tiago/Mestrado/Dissertacao/dataset/wine-white.data')#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_sample = 0.7\n",
    "test_sample = 0.3\n",
    "\n",
    "# 'auto'  = Testa tudo\n",
    "# 'tree'  = Decision Tree\n",
    "# 'naive' = Naive Bayes\n",
    "# 'svm'   = SVM\n",
    "choice = 'svm'\n",
    "\n",
    "# Parâmetros Naive\n",
    "# Nome = Smoothing\n",
    "#smoothing = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "smoothing = [round(x * 0.1, 1) for x in range(0, 100)]\n",
    "\n",
    "#smoothing = [1, 2, 3]\n",
    "naiveParam = Naive(smoothing)\n",
    "\n",
    "# Parâmetros SVM\n",
    "maxIter = [90,100,110,120,130]\n",
    "regParam = [0.0,0.5,1.0]\n",
    "svmParam = SVM(maxIter, regParam)\n",
    "\n",
    "# Parâmetros Decision Tree\n",
    "# Deapht / MaxIter\n",
    "maxDepth = [x for x in range(1, 31)] # 31 é o máximo\n",
    "maxBin = [32,64,128,256,512,1024]\n",
    "dtreeParam = Tree(maxDepth, maxBin)\n",
    "\n",
    "################\n",
    "\n",
    "\n",
    "#amostra = \"\"\n",
    "#execucao = \"dtree-MD-custom-30-40-CP-custom-15-30\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-Processamento/Tratamento Padrão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol=\"class\", outputCol=\"label\").fit(orig_data)\n",
    "label_data = indexer.transform(orig_data)\n",
    "\n",
    "labelReverse = IndexToString().setInputCol(\"label\")\n",
    "\n",
    "label_data = label_data.drop(\"class\")\n",
    "\n",
    "ignore = ['label']\n",
    "list = [x for x in label_data.columns if x not in ignore]\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "            inputCols=list,\n",
    "            outputCol='features')\n",
    "\n",
    "data = (assembler.transform(label_data).select(\"label\",\"features\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomSplit Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(train, test) = data.randomSplit([train_sample, test_sample], 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: SVM | Accuracy = 62.2 % | Time = 157.8 s | maxIter = 90.0 | regParam = 0.0\n",
      "Algorithm: SVM | Accuracy = 54.1 % | Time = 143.1 s | maxIter = 90.0 | regParam = 0.5\n",
      "Algorithm: SVM | Accuracy = 55.0 % | Time = 137.9 s | maxIter = 90.0 | regParam = 1.0\n",
      "Algorithm: SVM | Accuracy = 63.1 % | Time = 151.8 s | maxIter = 100.0 | regParam = 0.0\n",
      "Algorithm: SVM | Accuracy = 55.0 % | Time = 158.8 s | maxIter = 100.0 | regParam = 0.5\n",
      "Algorithm: SVM | Accuracy = 57.7 % | Time = 153.5 s | maxIter = 100.0 | regParam = 1.0\n",
      "Algorithm: SVM | Accuracy = 64.0 % | Time = 172.7 s | maxIter = 110.0 | regParam = 0.0\n",
      "Algorithm: SVM | Accuracy = 56.8 % | Time = 174.1 s | maxIter = 110.0 | regParam = 0.5\n",
      "Algorithm: SVM | Accuracy = 56.8 % | Time = 174.4 s | maxIter = 110.0 | regParam = 1.0\n",
      "Algorithm: SVM | Accuracy = 61.3 % | Time = 184.8 s | maxIter = 120.0 | regParam = 0.0\n",
      "Algorithm: SVM | Accuracy = 58.6 % | Time = 192.7 s | maxIter = 120.0 | regParam = 0.5\n",
      "Algorithm: SVM | Accuracy = 62.2 % | Time = 180.5 s | maxIter = 120.0 | regParam = 1.0\n",
      "Algorithm: SVM | Accuracy = 62.2 % | Time = 194.6 s | maxIter = 130.0 | regParam = 0.0\n",
      "Algorithm: SVM | Accuracy = 60.4 % | Time = 206.8 s | maxIter = 130.0 | regParam = 0.5\n",
      "Algorithm: SVM | Accuracy = 64.0 % | Time = 196.0 s | maxIter = 130.0 | regParam = 1.0\n",
      "Tempo Médio: 172.0 s\n",
      "Tempo Total: 2600.2 s\n"
     ]
    }
   ],
   "source": [
    "resul = []\n",
    "resul = autoChoice(train, test, choice, naiveParam, svmParam, dtreeParam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#graphic_2d(resul)\n",
    "#graphic_3d(resul)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: svm | Accuracy = 64.0 % | Time = 172.7 s | ParametroA = 110.0 | ParametroB = 0.0\n",
      "Algorithm: svm | Accuracy = 64.0 % | Time = 196.0 s | ParametroA = 130.0 | ParametroB = 1.0\n",
      "Algorithm: svm | Accuracy = 63.1 % | Time = 151.8 s | ParametroA = 100.0 | ParametroB = 0.0\n",
      "Algorithm: svm | Accuracy = 62.2 % | Time = 157.8 s | ParametroA = 90.0 | ParametroB = 0.0\n",
      "Algorithm: svm | Accuracy = 62.2 % | Time = 180.5 s | ParametroA = 120.0 | ParametroB = 1.0\n"
     ]
    }
   ],
   "source": [
    "# Exibe os Melhores Resultados em Ordem Decrescente\n",
    "resul.sort(key=lambda x: x.acuracia, reverse=True)\n",
    "for i in range(5):\n",
    "    print(\"Algorithm: %s | Accuracy = %3.1f %% | Time = %3.1f s | ParametroA = %3.1f | ParametroB = %3.1f\" % (resul[i].algoritmo, resul[i].acuracia, resul[i].tempo, resul[i].parametroA, resul[i].parametroB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: svm | Precisão = 100.0 % | False Positive = 0.0 % | Recall = 40.0 %\n"
     ]
    }
   ],
   "source": [
    "# Imprime Outros Resultados do Melhor Modelo\n",
    "print(\"Algorithm: %s | Precisão = %3.1f %% | False Positive = %3.1f %% | Recall = %3.1f %%\" % (resul[0].algoritmo, resul[0].precisao, resul[0].fpositivos, resul[0].recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
